"""
Correct Trust Definition and Implementation
æ­£ç¡®çš„Trustå®šä¹‰å’Œå®ç°

æ ¸å¿ƒåŒºåˆ«ï¼š
- Explanation Uncertainty: å½’å› æœ¬èº«çš„ç¨³å®šæ€§ï¼ˆattributionæ˜¯å¦ç¨³å®šï¼‰
- Trust: å½’å› å£°ç§°çš„å¯éªŒè¯æ€§ï¼ˆå½“attributionè¯´"é‡è¦"æ—¶ï¼Œæ¨¡å‹è¡Œä¸ºæ˜¯å¦æ”¯æŒï¼‰

Trust â‰  Uncertaintyï¼
Trustæ˜¯åœ¨æ¨¡å‹è¡Œä¸ºå±‚é¢éªŒè¯attributionçš„å£°ç§°ï¼Œè€Œä¸æ˜¯çœ‹attributionç¨³ä¸ç¨³ã€‚
"""

import numpy as np
import torch
import torch.nn as nn
from typing import Dict, Tuple, Optional, Callable
from scipy.stats import spearmanr


# ==================== æ ¸å¿ƒæ¦‚å¿µåŒºåˆ† ====================

class ExplanationUncertainty:
    """
    Explanation Uncertaintyï¼ˆè§£é‡Šä¸ç¡®å®šæ€§ï¼‰
    
    é—®é¢˜ï¼šè¿™ä¸ªé‡è¦æ€§åˆ¤æ–­ç¨³ä¸ç¨³ï¼Ÿ
    æ–¹æ³•ï¼šå¤šæ¬¡è®¡ç®—attributionï¼Œçœ‹æ–¹å·®
    
    è¿™åªæ˜¯stabilityï¼Œä¸æ˜¯trustï¼æ³¨æ„ï¼šè¿™é‡Œçš„æ–¹å·®æ¥æºäºè§£é‡Šè¿‡ç¨‹ä¸­
    çš„æ¨ç†éšæœºæ€§ï¼ˆå¦‚MC Dropoutï¼‰ï¼Œå¹¶ä¸ç­‰ä»·äºæ¨¡å‹æ•´ä½“çš„epistemic
    uncertaintyã€‚
    """
    
    @staticmethod
    def compute_uncertainty(
        attributions: np.ndarray  # [n_samples, length]
    ) -> np.ndarray:
        """
        è®¡ç®—attributionçš„ä¸ç¡®å®šæ€§
        
        Args:
            attributions: [n_samples, length] å¤šæ¬¡MC Dropoutçš„ç»“æœ
            
        Returns:
            uncertainty: [length] æ¯ä¸ªæ—¶é—´æ­¥çš„æ ‡å‡†å·®
        """
        return np.std(attributions, axis=0)


class TrustScore:
    """
    Trust Scoreï¼ˆå¯ä¿¡åº¦è¯„åˆ†ï¼‰
    
    æ ¸å¿ƒå®šä¹‰åˆ†ä¸ºä¸¤éƒ¨åˆ†ï¼š
    
    1. åŸºç¡€Trustï¼ˆé€šè¿‡æ‰°åŠ¨éªŒè¯ï¼‰ï¼š
       Trust(t|x) = E[ğŸ™(|f(x) - f(x\Î´_t)| â‰¥ Îµ) | a_t â‰¥ Ï„]
       é—®é¢˜ï¼šå½“attributionè¯´"tå¾ˆé‡è¦"æ—¶ï¼Œè¯¥ä¸è¯¥ä¿¡ï¼Ÿ
       æ–¹æ³•ï¼šæ‰°åŠ¨æ—¶é—´ç‚¹tï¼Œçœ‹æ¨¡å‹è¾“å‡ºæ˜¯å¦çœŸçš„å˜åŒ–
    
    2. èšåˆTrustï¼ˆæ•´åˆå¤šè§†å›¾ä¿¡æ¯ï¼‰ï¼š
       Trust_agg(t) = (1/R) Î£_r exp(-U_r(t)) Â· C_r(t) Â· A_r(t)
       
       å…¶ä¸­ï¼š
       - R: è§†å›¾æ•°é‡
       - U_r(t): è§†å›¾råœ¨æ—¶é—´æ­¥tçš„ä¸ç¡®å®šæ€§ï¼ˆuncertaintyï¼‰
       - C_r(t): è§†å›¾råœ¨æ—¶é—´æ­¥tçš„ä¸€è‡´æ€§ï¼ˆconsistencyï¼‰
       - A_r(t): è§†å›¾råœ¨æ—¶é—´æ­¥tçš„å½’å› å€¼ï¼ˆattributionï¼‰
       - exp(-U_r(t)): ä¸ç¡®å®šæ€§çš„æŒ‡æ•°è¡°å‡ï¼Œä½ä¸ç¡®å®šæ€§ â†’ é«˜æƒé‡
    
    Trust_aggç»¼åˆè€ƒè™‘ï¼š
    - ä½ä¸ç¡®å®šæ€§çš„è§†å›¾æƒé‡æ›´é«˜ï¼ˆé€šè¿‡exp(-U)ï¼‰
    - é«˜ä¸€è‡´æ€§çš„æ—¶é—´æ­¥æ›´å¯ä¿¡
    - å½’å› å€¼æœ¬èº«çš„å¤§å°
    
    å…³é”®ï¼š
    1. åªåœ¨attributionå£°ç§°"é‡è¦"æ—¶è¯„ä¼°ï¼ˆæ¡ä»¶åŒ–ï¼‰
    2. é€šè¿‡æ¨¡å‹è¡Œä¸ºéªŒè¯ï¼Œä¸æ˜¯çœ‹attributionç¨³å®šæ€§
    3. TrustéªŒè¯çš„æ˜¯"é‡è¦æ€§å£°ç§°" vs "å®é™…å½±å“"
    4. Trust_aggæ•´åˆäº†å¤šè§†å›¾ã€ä¸ç¡®å®šæ€§å’Œä¸€è‡´æ€§ä¿¡æ¯
    """
    
    def __init__(
        self,
        model: nn.Module,
        device: str = 'cuda',
        epsilon: float = 0.1,  # æ¨¡å‹è¾“å‡ºå˜åŒ–é˜ˆå€¼
        importance_threshold: float = 0.5  # attributioné‡è¦æ€§é˜ˆå€¼
    ):
        self.model = model
        self.device = device
        self.epsilon = epsilon
        self.importance_threshold = importance_threshold
        self.model.eval()
    
    def _perturb_timestep(
        self,
        x: torch.Tensor,
        t: int,
        perturbation_type: str = 'zero',
        magnitude: float = 0.2
    ) -> torch.Tensor:
        """
        æ‰°åŠ¨å•ä¸ªæ—¶é—´æ­¥ï¼ˆè¯­ä¹‰ä¿æŒæ‰°åŠ¨ï¼‰
        
        Args:
            x: [1, channels, length]
            t: æ—¶é—´æ­¥ç´¢å¼•
            perturbation_type: 'zero', 'noise', 'shuffle'
            magnitude: æ‰°åŠ¨å¹…åº¦
            
        Returns:
            perturbed_x: æ‰°åŠ¨åçš„è¾“å…¥
        """
        x_pert = x.clone()
        
        if perturbation_type == 'zero':
            # ç½®é›¶ï¼ˆæœ€å¼ºæ‰°åŠ¨ï¼‰
            x_pert[:, :, t] = 0
            
        elif perturbation_type == 'noise':
            # åŠ å™ªå£°
            noise = torch.randn_like(x[:, :, t]) * magnitude
            x_pert[:, :, t] += noise
            
        elif perturbation_type == 'shuffle':
            # å±€éƒ¨æ‰“ä¹±ï¼ˆç ´åæ—¶åºï¼‰
            window = 5
            start = max(0, t - window // 2)
            end = min(x.shape[-1], t + window // 2 + 1)
            indices = torch.randperm(end - start) + start
            x_pert[:, :, start:end] = x[:, :, indices]
            
        else:
            raise ValueError(f"Unknown perturbation type: {perturbation_type}")
        
        return x_pert
    
    def _compute_output_change(
        self,
        x: torch.Tensor,
        x_perturbed: torch.Tensor,
        metric: str = 'prediction_change'
    ) -> float:
        """
        è®¡ç®—æ¨¡å‹è¾“å‡ºçš„å˜åŒ–ç¨‹åº¦
        
        Args:
            x: åŸå§‹è¾“å…¥
            x_perturbed: æ‰°åŠ¨åçš„è¾“å…¥
            metric: 'prediction_change', 'confidence_drop', 'logit_diff'
                å½“ metric='confidence_drop'ï¼ˆé»˜è®¤ï¼‰æ—¶ï¼ŒÎµ çš„è¯­ä¹‰å¯¹åº”äº
                Softmaxç½®ä¿¡åº¦çš„ä¸‹é™é‡ã€‚
            
        Returns:
            change: è¾“å‡ºå˜åŒ–é‡
        """
        with torch.no_grad():
            output_orig = self.model(x.to(self.device))
            output_pert = self.model(x_perturbed.to(self.device))
            
            if metric == 'prediction_change':
                # é¢„æµ‹æ˜¯å¦æ”¹å˜ï¼ˆ0æˆ–1ï¼‰
                pred_orig = output_orig.argmax(dim=-1)
                pred_pert = output_pert.argmax(dim=-1)
                change = float(pred_orig != pred_pert)
                
            elif metric == 'confidence_drop':
                # ç½®ä¿¡åº¦ä¸‹é™
                prob_orig = torch.softmax(output_orig, dim=-1)
                prob_pert = torch.softmax(output_pert, dim=-1)
                target_class = output_orig.argmax(dim=-1)
                
                conf_orig = prob_orig[0, target_class].item()
                conf_pert = prob_pert[0, target_class].item()
                change = conf_orig - conf_pert
                
            elif metric == 'logit_diff':
                # Logitå·®å¼‚
                change = torch.abs(output_orig - output_pert).max().item()
                
            else:
                raise ValueError(f"Unknown metric: {metric}")
        
        return change
    
    def compute_trust_single_timestep(
        self,
        x: torch.Tensor,
        t: int,
        attribution_value: float,
        n_perturbations: int = 20,
        perturbation_types: list = ['zero', 'noise']
    ) -> float:
        """
        è®¡ç®—å•ä¸ªæ—¶é—´æ­¥çš„trust
        
        Trust(t|x) = P(æ¨¡å‹è¾“å‡ºæ˜¾è‘—å˜åŒ– | attributionè¯´té‡è¦)
        
        Args:
            x: è¾“å…¥æ ·æœ¬
            t: æ—¶é—´æ­¥
            attribution_value: è¯¥æ—¶é—´æ­¥çš„attributionå€¼
            n_perturbations: æ¯ç§æ‰°åŠ¨ç±»å‹çš„é‡å¤æ¬¡æ•°
            perturbation_types: æ‰°åŠ¨ç±»å‹åˆ—è¡¨
            
        Returns:
            trust: [0, 1] å¯ä¿¡åº¦åˆ†æ•°
        """
        # å½’ä¸€åŒ–attributionå€¼
        attr_norm = abs(attribution_value)
        
        # åªåœ¨attributionå£°ç§°"é‡è¦"æ—¶è®¡ç®—trust
        if attr_norm < self.importance_threshold:
            # è‹¥è§£é‡Šæœªå£°ç§°é‡è¦ï¼Œåˆ™ Trust(t|x) æœªå®šä¹‰ï¼Œè¿”å›NaN
            return np.nan
        
        # æ”¶é›†å¤šæ¬¡æ‰°åŠ¨çš„ç»“æœ
        significant_changes = []
        
        for pert_type in perturbation_types:
            for _ in range(n_perturbations):
                # æ‰°åŠ¨æ—¶é—´æ­¥t
                x_pert = self._perturb_timestep(x, t, pert_type)
                
                # è®¡ç®—è¾“å‡ºå˜åŒ–
                change = self._compute_output_change(
                    x, x_pert, metric='confidence_drop'
                )
                
                # åˆ¤æ–­æ˜¯å¦æ˜¾è‘—å˜åŒ–
                significant_changes.append(change >= self.epsilon)
        
        # Trust = æ˜¾è‘—å˜åŒ–çš„æ¯”ä¾‹
        trust = np.mean(significant_changes)
        
        return trust
    
    def compute_trust_all_timesteps(
        self,
        x: torch.Tensor,
        attribution: np.ndarray,
        n_perturbations: int = 5
    ) -> np.ndarray:
        """
        è®¡ç®—æ‰€æœ‰æ—¶é—´æ­¥çš„trust
        
        Args:
            x: [1, channels, length]
            attribution: [length]
            n_perturbations: æ¯ä¸ªæ—¶é—´æ­¥çš„æ‰°åŠ¨æ¬¡æ•°
            
        Returns:
            trust_scores: [length]
        """
        length = attribution.shape[0]
        trust_scores = np.zeros(length)
        
        for t in range(length):
            trust_scores[t] = self.compute_trust_single_timestep(
                x, t, attribution[t], n_perturbations
            )
        
        return trust_scores
    
    @staticmethod
    def _importance_gate(
        attributions: np.ndarray,
        threshold: float = 0.5,
        eps: float = 1e-8,
        normalize: bool = True
    ) -> np.ndarray:
        """Soft gating that activates only when |a_t| surpasses threshold."""
        abs_attr = np.abs(attributions)
        if normalize:
            # å°†æ¯ä¸ªè§†å›¾çš„attributionç¼©æ”¾åˆ°[0, 1]
            max_abs = abs_attr.max(axis=-1, keepdims=True)
            max_abs = np.where(max_abs < eps, eps, max_abs)
            abs_attr = abs_attr / max_abs
        gate = (abs_attr - threshold) / (1.0 - threshold + eps)
        return np.clip(gate, 0.0, 1.0)

    @staticmethod
    def compute_trust_aggregated(
        attributions_by_view,
        uncertainties_by_view,
        consistencies: np.ndarray,
        beta: float = 0.5,
        gamma: float = 0.5,
        importance_threshold: float = 0.5,
        gate_normalize: bool = True,
        alpha: float = 1.0
    ) -> np.ndarray:
        """
        Trust_agg(t) = E_r[ gate(|a_r(t)|) Â· exp(-beta U_r(t)) ] Â· Consistency(t)^gamma
        """
        if isinstance(attributions_by_view, dict):
            attr_stack = np.stack([np.abs(v) for v in attributions_by_view.values()])
        else:
            attr_stack = np.abs(np.asarray(attributions_by_view))
        if isinstance(uncertainties_by_view, dict):
            unc_stack = np.stack(list(uncertainties_by_view.values()))
        else:
            unc_stack = np.asarray(uncertainties_by_view)

        gate = TrustScore._importance_gate(
            attr_stack,
            threshold=importance_threshold,
            normalize=gate_normalize
        )
        if alpha != 1.0:
            gate = np.power(gate, alpha)
        reliability = np.exp(-beta * unc_stack)
        view_scores = gate * reliability
        mean_view_weight = np.nanmean(view_scores, axis=0)

        consistency_clamped = np.clip(consistencies, 0.0, 1.0)
        consistency_weight = np.power(consistency_clamped, gamma)
        trust = consistency_weight * mean_view_weight
        return np.clip(trust, 0.0, 1.0)
    
    @staticmethod
    def compute_trust_aggregated_normalized(
        attributions_by_view: dict,
        uncertainties_by_view: dict,
        consistencies: np.ndarray
    ) -> np.ndarray:
        return TrustScore.compute_trust_aggregated(
            attributions_by_view,
            uncertainties_by_view,
            consistencies
        )

    @staticmethod
    def compute_trusted_importance(
        attributions_by_view,
        trust: np.ndarray
    ) -> np.ndarray:
        if isinstance(attributions_by_view, dict):
            attr_stack = np.stack(
                [np.abs(attr) for attr in attributions_by_view.values()]
            )
        else:
            attr_stack = np.abs(np.asarray(attributions_by_view))
        mean_attr = attr_stack.mean(axis=0)
        return trust * mean_attr


# ==================== æ—¶é—´æ­¥çº§åˆ«ä¸€è‡´æ€§ ====================

class TimestepConsistency:
    """
    Time-step-level Cross-view Consistency
    
    é—®é¢˜ï¼šä¸åŒè§†å›¾åœ¨æ¯ä¸ªæ—¶é—´æ­¥ä¸Šçš„attributionæ˜¯å¦ä¸€è‡´
    æ³¨æ„ï¼šè¿™æ˜¯æ—¶é—´æ­¥çº§åˆ«ï¼Œä¸æ˜¯å…¨å±€ç›¸ä¼¼åº¦
    """
    
    @staticmethod
    # def compute_timestep_consistency(
    #     attributions: Dict[str, np.ndarray],  # {view_name: [length]}
    #     method: str = 'inverse_std'
    # ) -> np.ndarray:
    #     """
    #     è®¡ç®—æ¯ä¸ªæ—¶é—´æ­¥çš„è·¨è§†å›¾ä¸€è‡´æ€§
        
    #     Args:
    #         attributions: {view_name: attribution[length]}
    #         method: 'inverse_std', 'inverse_range', 'inverse_cv'
            
    #     Returns:
    #         consistency: [length] æ¯ä¸ªæ—¶é—´æ­¥çš„ä¸€è‡´æ€§
    #     """
    #     view_names = list(attributions.keys())
    #     length = attributions[view_names[0]].shape[0]
        
    #     consistency = np.zeros(length)
        
    #     for t in range(length):
    #         # æ”¶é›†è¯¥æ—¶é—´æ­¥åœ¨æ‰€æœ‰viewä¸­çš„å€¼
    #         values_at_t = np.array([attributions[v][t] for v in view_names])
            
    #         if method == 'inverse_std':
    #             # æ ‡å‡†å·®çš„å€’æ•°
    #             std = np.std(values_at_t)
    #             consistency[t] = 1.0 / (1.0 + std)
                
    #         elif method == 'inverse_range':
    #             # èŒƒå›´çš„å€’æ•°
    #             value_range = np.ptp(values_at_t)  # peak-to-peak
    #             consistency[t] = 1.0 / (1.0 + value_range)
                
    #         elif method == 'inverse_cv':
    #             # å˜å¼‚ç³»æ•°çš„å€’æ•°
    #             mean = np.mean(values_at_t)
    #             std = np.std(values_at_t)
    #             cv = std / (abs(mean) + 1e-8)
    #             consistency[t] = 1.0 / (1.0 + cv)
                
    #         elif method == 'cosine_global':
    #             stacked = np.stack([attributions[v] for v in view_names])
    #             norms = np.linalg.norm(stacked, axis=1, keepdims=True)
    #             normalized = stacked / (norms + 1e-8)
    #             sim_matrix = normalized @ normalized.T
    #             mask = ~np.eye(len(view_names), dtype=bool)
    #             if mask.sum() == 0:
    #                 mean_sim = 1.0
    #             else:
    #                 mean_sim = sim_matrix[mask].mean()
    #             mean_sim = np.clip(mean_sim, 0.0, 1.0)
    #             consistency[:] = mean_sim
    #             break
    #         else:
    #             raise ValueError(f"Unknown method: {method}")
        
    #     return consistency

    def compute_timestep_consistency(attributions: Dict[str, np.ndarray], method: str = 'inverse_std') -> np.ndarray:
        view_names = list(attributions.keys())
        length = attributions[view_names[0]].shape[0]
        R = len(view_names)

        consistency = np.zeros(length)

        for t in range(length):
            vals = np.array([attributions[v][t] for v in view_names])

            # 1. sign agreement
            signs = np.sign(vals)
            agree = 0
            total = 0
            for i in range(R):
                for j in range(i + 1, R):
                    total += 1
                    agree += int(signs[i] == signs[j])
            sign_agreement = agree / (total + 1e-8)

            # 2. magnitude tolerance (log-scale)
            mags = np.abs(vals) + 1e-8
            mag_var = np.var(np.log(mags))
            mag_consistency = np.exp(-mag_var)

            consistency[t] = sign_agreement * mag_consistency
            consistency[t] = consistency[t] ** 0.5  # å¹³æ–¹æ ¹è°ƒæ•´å°ºåº¦

        return consistency

# ==================== æ ¸å¿ƒåŒºåˆ†ï¼šä¸‰ä¸ªæ¦‚å¿µ ====================

class ThreeConceptsDistinction:
    """
    æ˜ç¡®åŒºåˆ†ä¸‰ä¸ªæ¦‚å¿µï¼š
    1. Attribution Importanceï¼ˆå½’å› é‡è¦æ€§ï¼‰
    2. Explanation Uncertaintyï¼ˆè§£é‡Šä¸ç¡®å®šæ€§ï¼‰
    3. Trustï¼ˆå¯ä¿¡åº¦ï¼‰
    """
    
    @staticmethod
    def categorize_timesteps(
        attribution: np.ndarray,         # [length] é‡è¦æ€§
        uncertainty: np.ndarray,         # [length] ä¸ç¡®å®šæ€§
        trust: np.ndarray,               # [length] å¯ä¿¡åº¦
        importance_threshold: float = 0.5,
        trust_threshold: float = 0.5
    ) -> Dict[str, np.ndarray]:
        """
        å°†æ—¶é—´æ­¥åˆ†ä¸ºå…«ç±»ï¼ˆ2Ã—2Ã—2ï¼‰
        
        ä½†æœ€å…³é”®çš„å¯¹æ¯”æ˜¯ï¼š
        - High importance + Low uncertainty + Low trust  â†’ ç¨³å®šä½†ä¸å¯ä¿¡
        - High importance + High uncertainty + High trust â†’ ä¸ç¨³å®šä½†å¯ä¿¡
        
        è¿™è¯æ˜äº†ï¼šUncertainty â‰  Trustï¼
        """
        # å½’ä¸€åŒ–
        attr_norm = np.abs(attribution)
        attr_norm = (attr_norm - attr_norm.min()) / (attr_norm.max() - attr_norm.min() + 1e-8)
        
        unc_norm = uncertainty / (uncertainty.max() + 1e-8)
        
        # åˆ†ç±»
        is_important = attr_norm > importance_threshold
        is_uncertain = unc_norm > 0.5  # é«˜ä¸ç¡®å®šæ€§
        is_trusted = trust > trust_threshold
        
        categories = {
            # å…³é”®å¯¹æ¯”1ï¼šç¨³å®šä½†ä¸å¯ä¿¡
            'stable_but_untrusted': np.where(
                is_important & ~is_uncertain & ~is_trusted
            )[0],
            
            # å…³é”®å¯¹æ¯”2ï¼šä¸ç¨³å®šä½†å¯ä¿¡
            'unstable_but_trusted': np.where(
                is_important & is_uncertain & is_trusted
            )[0],
            
            # ç†æƒ³æƒ…å†µï¼šç¨³å®šä¸”å¯ä¿¡
            'stable_and_trusted': np.where(
                is_important & ~is_uncertain & is_trusted
            )[0],
            
            # æœ€å·®æƒ…å†µï¼šä¸ç¨³å®šä¸”ä¸å¯ä¿¡
            'unstable_and_untrusted': np.where(
                is_important & is_uncertain & ~is_trusted
            )[0],
            
            # å…¶ä»–ç±»åˆ«
            'unimportant_stable_trusted': np.where(
                ~is_important & ~is_uncertain & is_trusted
            )[0],
            
            'unimportant_stable_untrusted': np.where(
                ~is_important & ~is_uncertain & ~is_trusted
            )[0],
            
            'unimportant_unstable_trusted': np.where(
                ~is_important & is_uncertain & is_trusted
            )[0],
            
            'unimportant_unstable_untrusted': np.where(
                ~is_important & is_uncertain & ~is_trusted
            )[0],
        }
        
        return categories


# ==================== ä½¿ç”¨ç¤ºä¾‹ ====================

if __name__ == "__main__":
    print("="*70)
    print("æ­£ç¡®çš„Trustå®šä¹‰å’Œå®ç°")
    print("="*70)
    
    print("\næ ¸å¿ƒåŒºåˆ«:")
    print("-"*70)
    print("Explanation Uncertainty:")
    print("  é—®é¢˜: è¿™ä¸ªé‡è¦æ€§åˆ¤æ–­ç¨³ä¸ç¨³ï¼Ÿ")
    print("  æ–¹æ³•: å¤šæ¬¡è®¡ç®—attributionï¼Œçœ‹æ–¹å·®")
    print("  æœ¬è´¨: Attributionæœ¬èº«çš„stability")
    
    print("\nTrust (åŸºç¡€å®šä¹‰):")
    print("  é—®é¢˜: å½“attributionè¯´'é‡è¦'æ—¶ï¼Œè¯¥ä¸è¯¥ä¿¡ï¼Ÿ")
    print("  æ–¹æ³•: æ‰°åŠ¨æ—¶é—´ç‚¹ï¼Œçœ‹æ¨¡å‹è¾“å‡ºæ˜¯å¦çœŸçš„å˜åŒ–")
    print("  æœ¬è´¨: Attributionå£°ç§°çš„å¯éªŒè¯æ€§ï¼ˆclaim verificationï¼‰")
    
    print("\nTrust_agg (èšåˆå®šä¹‰ï¼Œæ¨è):")
    print("  å…¬å¼: Trust_agg(t) = (1/R) Î£_r exp(-U_r(t)) Â· C_r(t) Â· A_r(t)")
    print("  æ•´åˆ: å¤šè§†å›¾ + ä¸ç¡®å®šæ€§ + ä¸€è‡´æ€§ + å½’å› å€¼")
    print("  ä¼˜ç‚¹: è®¡ç®—å¿«é€Ÿï¼Œä¸éœ€è¦é¢å¤–æ‰°åŠ¨")
    
    print("\nå…³é”®æ´å¯Ÿ:")
    print("-"*70)
    print("âŒ Low uncertainty â‰  High trust")
    print("âœ“ Trust_aggè‡ªåŠ¨é™ä½ä¸ç¡®å®šè§†å›¾çš„æƒé‡ï¼ˆexp(-U)ï¼‰")
    print("âœ“ Trust_aggå¼ºè°ƒè·¨è§†å›¾ä¸€è‡´çš„æ—¶é—´æ­¥ï¼ˆCï¼‰")
    print("âœ“ Trust_aggè€ƒè™‘å½’å› å€¼å¤§å°ï¼ˆAï¼‰")
    
    print("\nTrustçš„ä¸¤ç§è®¡ç®—æ–¹å¼:")
    print("-"*70)
    print("1. æ‰°åŠ¨éªŒè¯ï¼ˆç²¾ç¡®ä½†æ…¢ï¼‰:")
    print("   Trust(t|x) = E[ğŸ™(|f(x) - f(x\\Î´_t)| â‰¥ Îµ) | a_t â‰¥ Ï„]")
    
    print("\n2. èšåˆå…¬å¼ï¼ˆå¿«é€Ÿä¸”æœ‰æ•ˆï¼Œæ¨èï¼‰:")
    print("   Trust_agg(t) = (1/R) Î£_r exp(-U_r(t)) Â· C_r(t) Â· A_r(t)")
    print("   - R: è§†å›¾æ•°é‡")
    print("   - U_r(t): è§†å›¾rçš„ä¸ç¡®å®šæ€§")
    print("   - C_r(t): æ—¶é—´æ­¥tçš„è·¨è§†å›¾ä¸€è‡´æ€§")
    print("   - A_r(t): è§†å›¾rçš„å½’å› å€¼")
    
    print("\n" + "="*70)
    print("æ¨¡å—å·²åŠ è½½ï¼Œå¯ä»¥ä½¿ç”¨ï¼š")
    print("  - ExplanationUncertainty: è®¡ç®—è§£é‡Šä¸ç¡®å®šæ€§")
    print("  - TrustScore.compute_trust_all_timesteps: æ‰°åŠ¨éªŒè¯æ–¹æ³•")
    print("  - TrustScore.compute_trust_aggregated: Trust_aggæ–¹æ³•ï¼ˆæ¨èï¼‰")
    print("  - TimestepConsistency: æ—¶é—´æ­¥çº§åˆ«ä¸€è‡´æ€§")
    print("  - ThreeConceptsDistinction: ä¸‰æ¦‚å¿µåŒºåˆ†")
    print("="*70)