"""
Correct Trust Definition and Implementation
æ­£ç¡®çš„Trustå®šä¹‰å’Œå®ç°

æ ¸å¿ƒåŒºåˆ«ï¼š
- Explanation Uncertainty: å½’å› æœ¬èº«çš„ç¨³å®šæ€§ï¼ˆattributionæ˜¯å¦ç¨³å®šï¼‰
- Trust: å½’å› å£°ç§°çš„å¯éªŒè¯æ€§ï¼ˆå½“attributionè¯´"é‡è¦"æ—¶ï¼Œæ¨¡å‹è¡Œä¸ºæ˜¯å¦æ”¯æŒï¼‰

Trust â‰  Uncertaintyï¼
Trustæ˜¯åœ¨æ¨¡å‹è¡Œä¸ºå±‚é¢éªŒè¯attributionçš„å£°ç§°ï¼Œè€Œä¸æ˜¯çœ‹attributionç¨³ä¸ç¨³ã€‚
"""

import numpy as np
import torch
import torch.nn as nn
from typing import Dict, Tuple, Optional, Callable
from scipy.stats import spearmanr


# ==================== æ ¸å¿ƒæ¦‚å¿µåŒºåˆ† ====================

class ExplanationUncertainty:
    """
    Explanation Uncertaintyï¼ˆè§£é‡Šä¸ç¡®å®šæ€§ï¼‰
    
    é—®é¢˜ï¼šè¿™ä¸ªé‡è¦æ€§åˆ¤æ–­ç¨³ä¸ç¨³ï¼Ÿ
    æ–¹æ³•ï¼šå¤šæ¬¡è®¡ç®—attributionï¼Œçœ‹æ–¹å·®
    
    è¿™åªæ˜¯stabilityï¼Œä¸æ˜¯trustï¼
    """
    
    @staticmethod
    def compute_uncertainty(
        attributions: np.ndarray  # [n_samples, length]
    ) -> np.ndarray:
        """
        è®¡ç®—attributionçš„ä¸ç¡®å®šæ€§
        
        Args:
            attributions: [n_samples, length] å¤šæ¬¡MC Dropoutçš„ç»“æœ
            
        Returns:
            uncertainty: [length] æ¯ä¸ªæ—¶é—´æ­¥çš„æ ‡å‡†å·®
        """
        return np.std(attributions, axis=0)


class TrustScore:
    """
    Trust Scoreï¼ˆå¯ä¿¡åº¦è¯„åˆ†ï¼‰
    
    æ ¸å¿ƒå®šä¹‰åˆ†ä¸ºä¸¤éƒ¨åˆ†ï¼š
    
    1. åŸºç¡€Trustï¼ˆé€šè¿‡æ‰°åŠ¨éªŒè¯ï¼‰ï¼š
       Trust(t|x) = E[ğŸ™(|f(x) - f(x\Î´_t)| â‰¥ Îµ) | a_t â‰¥ Ï„]
       é—®é¢˜ï¼šå½“attributionè¯´"tå¾ˆé‡è¦"æ—¶ï¼Œè¯¥ä¸è¯¥ä¿¡ï¼Ÿ
       æ–¹æ³•ï¼šæ‰°åŠ¨æ—¶é—´ç‚¹tï¼Œçœ‹æ¨¡å‹è¾“å‡ºæ˜¯å¦çœŸçš„å˜åŒ–
    
    2. èšåˆTrustï¼ˆæ•´åˆå¤šè§†å›¾ä¿¡æ¯ï¼‰ï¼š
       Trust_agg(t) = (1/R) Î£_r exp(-U_r(t)) Â· C_r(t) Â· A_r(t)
       
       å…¶ä¸­ï¼š
       - R: è§†å›¾æ•°é‡
       - U_r(t): è§†å›¾råœ¨æ—¶é—´æ­¥tçš„ä¸ç¡®å®šæ€§ï¼ˆuncertaintyï¼‰
       - C_r(t): è§†å›¾råœ¨æ—¶é—´æ­¥tçš„ä¸€è‡´æ€§ï¼ˆconsistencyï¼‰
       - A_r(t): è§†å›¾råœ¨æ—¶é—´æ­¥tçš„å½’å› å€¼ï¼ˆattributionï¼‰
       - exp(-U_r(t)): ä¸ç¡®å®šæ€§çš„æŒ‡æ•°è¡°å‡ï¼Œä½ä¸ç¡®å®šæ€§ â†’ é«˜æƒé‡
    
    Trust_aggç»¼åˆè€ƒè™‘ï¼š
    - ä½ä¸ç¡®å®šæ€§çš„è§†å›¾æƒé‡æ›´é«˜ï¼ˆé€šè¿‡exp(-U)ï¼‰
    - é«˜ä¸€è‡´æ€§çš„æ—¶é—´æ­¥æ›´å¯ä¿¡
    - å½’å› å€¼æœ¬èº«çš„å¤§å°
    
    å…³é”®ï¼š
    1. åªåœ¨attributionå£°ç§°"é‡è¦"æ—¶è¯„ä¼°ï¼ˆæ¡ä»¶åŒ–ï¼‰
    2. é€šè¿‡æ¨¡å‹è¡Œä¸ºéªŒè¯ï¼Œä¸æ˜¯çœ‹attributionç¨³å®šæ€§
    3. TrustéªŒè¯çš„æ˜¯"é‡è¦æ€§å£°ç§°" vs "å®é™…å½±å“"
    4. Trust_aggæ•´åˆäº†å¤šè§†å›¾ã€ä¸ç¡®å®šæ€§å’Œä¸€è‡´æ€§ä¿¡æ¯
    """
    
    def __init__(
        self,
        model: nn.Module,
        device: str = 'cuda',
        epsilon: float = 0.1,  # æ¨¡å‹è¾“å‡ºå˜åŒ–é˜ˆå€¼
        importance_threshold: float = 0.5  # attributioné‡è¦æ€§é˜ˆå€¼
    ):
        self.model = model
        self.device = device
        self.epsilon = epsilon
        self.importance_threshold = importance_threshold
        self.model.eval()
    
    def _perturb_timestep(
        self,
        x: torch.Tensor,
        t: int,
        perturbation_type: str = 'zero',
        magnitude: float = 0.2
    ) -> torch.Tensor:
        """
        æ‰°åŠ¨å•ä¸ªæ—¶é—´æ­¥ï¼ˆè¯­ä¹‰ä¿æŒæ‰°åŠ¨ï¼‰
        
        Args:
            x: [1, channels, length]
            t: æ—¶é—´æ­¥ç´¢å¼•
            perturbation_type: 'zero', 'noise', 'shuffle'
            magnitude: æ‰°åŠ¨å¹…åº¦
            
        Returns:
            perturbed_x: æ‰°åŠ¨åçš„è¾“å…¥
        """
        x_pert = x.clone()
        
        if perturbation_type == 'zero':
            # ç½®é›¶ï¼ˆæœ€å¼ºæ‰°åŠ¨ï¼‰
            x_pert[:, :, t] = 0
            
        elif perturbation_type == 'noise':
            # åŠ å™ªå£°
            noise = torch.randn_like(x[:, :, t]) * magnitude
            x_pert[:, :, t] += noise
            
        elif perturbation_type == 'shuffle':
            # å±€éƒ¨æ‰“ä¹±ï¼ˆç ´åæ—¶åºï¼‰
            window = 5
            start = max(0, t - window // 2)
            end = min(x.shape[-1], t + window // 2 + 1)
            indices = torch.randperm(end - start) + start
            x_pert[:, :, start:end] = x[:, :, indices]
            
        else:
            raise ValueError(f"Unknown perturbation type: {perturbation_type}")
        
        return x_pert
    
    def _compute_output_change(
        self,
        x: torch.Tensor,
        x_perturbed: torch.Tensor,
        metric: str = 'prediction_change'
    ) -> float:
        """
        è®¡ç®—æ¨¡å‹è¾“å‡ºçš„å˜åŒ–ç¨‹åº¦
        
        Args:
            x: åŸå§‹è¾“å…¥
            x_perturbed: æ‰°åŠ¨åçš„è¾“å…¥
            metric: 'prediction_change', 'confidence_drop', 'logit_diff'
            
        Returns:
            change: è¾“å‡ºå˜åŒ–é‡
        """
        with torch.no_grad():
            output_orig = self.model(x.to(self.device))
            output_pert = self.model(x_perturbed.to(self.device))
            
            if metric == 'prediction_change':
                # é¢„æµ‹æ˜¯å¦æ”¹å˜ï¼ˆ0æˆ–1ï¼‰
                pred_orig = output_orig.argmax(dim=-1)
                pred_pert = output_pert.argmax(dim=-1)
                change = float(pred_orig != pred_pert)
                
            elif metric == 'confidence_drop':
                # ç½®ä¿¡åº¦ä¸‹é™
                prob_orig = torch.softmax(output_orig, dim=-1)
                prob_pert = torch.softmax(output_pert, dim=-1)
                target_class = output_orig.argmax(dim=-1)
                
                conf_orig = prob_orig[0, target_class].item()
                conf_pert = prob_pert[0, target_class].item()
                change = conf_orig - conf_pert
                
            elif metric == 'logit_diff':
                # Logitå·®å¼‚
                change = torch.abs(output_orig - output_pert).max().item()
                
            else:
                raise ValueError(f"Unknown metric: {metric}")
        
        return change
    
    def compute_trust_single_timestep(
        self,
        x: torch.Tensor,
        t: int,
        attribution_value: float,
        n_perturbations: int = 20,
        perturbation_types: list = ['zero', 'noise']
    ) -> float:
        """
        è®¡ç®—å•ä¸ªæ—¶é—´æ­¥çš„trust
        
        Trust(t|x) = P(æ¨¡å‹è¾“å‡ºæ˜¾è‘—å˜åŒ– | attributionè¯´té‡è¦)
        
        Args:
            x: è¾“å…¥æ ·æœ¬
            t: æ—¶é—´æ­¥
            attribution_value: è¯¥æ—¶é—´æ­¥çš„attributionå€¼
            n_perturbations: æ¯ç§æ‰°åŠ¨ç±»å‹çš„é‡å¤æ¬¡æ•°
            perturbation_types: æ‰°åŠ¨ç±»å‹åˆ—è¡¨
            
        Returns:
            trust: [0, 1] å¯ä¿¡åº¦åˆ†æ•°
        """
        # å½’ä¸€åŒ–attributionå€¼
        attr_norm = abs(attribution_value)
        
        # åªåœ¨attributionå£°ç§°"é‡è¦"æ—¶è®¡ç®—trust
        if attr_norm < self.importance_threshold:
            # å¦‚æœattributionæœ¬èº«å°±è¯´"ä¸é‡è¦"ï¼Œtrustæ— æ„ä¹‰
            return 0.0
        
        # æ”¶é›†å¤šæ¬¡æ‰°åŠ¨çš„ç»“æœ
        significant_changes = []
        
        for pert_type in perturbation_types:
            for _ in range(n_perturbations):
                # æ‰°åŠ¨æ—¶é—´æ­¥t
                x_pert = self._perturb_timestep(x, t, pert_type)
                
                # è®¡ç®—è¾“å‡ºå˜åŒ–
                change = self._compute_output_change(
                    x, x_pert, metric='confidence_drop'
                )
                
                # åˆ¤æ–­æ˜¯å¦æ˜¾è‘—å˜åŒ–
                significant_changes.append(change >= self.epsilon)
        
        # Trust = æ˜¾è‘—å˜åŒ–çš„æ¯”ä¾‹
        trust = np.mean(significant_changes)
        
        return trust
    
    def compute_trust_all_timesteps(
        self,
        x: torch.Tensor,
        attribution: np.ndarray,
        n_perturbations: int = 5
    ) -> np.ndarray:
        """
        è®¡ç®—æ‰€æœ‰æ—¶é—´æ­¥çš„trust
        
        Args:
            x: [1, channels, length]
            attribution: [length]
            n_perturbations: æ¯ä¸ªæ—¶é—´æ­¥çš„æ‰°åŠ¨æ¬¡æ•°
            
        Returns:
            trust_scores: [length]
        """
        length = attribution.shape[0]
        trust_scores = np.zeros(length)
        
        for t in range(length):
            trust_scores[t] = self.compute_trust_single_timestep(
                x, t, attribution[t], n_perturbations
            )
        
        return trust_scores
    
    @staticmethod
    def compute_trust_aggregated(
        attributions_by_view: dict,      # {view_name: attribution[length]}
        uncertainties_by_view: dict,     # {view_name: uncertainty[length]}
        consistencies: np.ndarray,       # [length] æ—¶é—´æ­¥çº§åˆ«ä¸€è‡´æ€§
        use_exponential_decay: bool = True
    ) -> np.ndarray:
        """
        è®¡ç®—èšåˆTruståˆ†æ•°ï¼ˆTrust_aggï¼‰
        
        Trust_agg(t) = (1/R) Î£_r exp(-U_r(t)) Â· C_r(t) Â· A_r(t)
        
        Args:
            attributions_by_view: {view_name: attribution[length]}
            uncertainties_by_view: {view_name: uncertainty[length]}
            consistencies: [length] æ¯ä¸ªæ—¶é—´æ­¥çš„è·¨è§†å›¾ä¸€è‡´æ€§
            use_exponential_decay: æ˜¯å¦ä½¿ç”¨exp(-U)ï¼Œå¦åˆ™ç”¨1/(1+U)
            
        Returns:
            trust_agg: [length] èšåˆçš„truståˆ†æ•°
        """
        view_names = list(attributions_by_view.keys())
        R = len(view_names)  # è§†å›¾æ•°é‡
        length = attributions_by_view[view_names[0]].shape[0]
        
        trust_agg = np.zeros(length)
        
        for t in range(length):
            weighted_sum = 0.0
            
            for view_name in view_names:
                A_r_t = attributions_by_view[view_name][t]  # å½’å› å€¼
                U_r_t = uncertainties_by_view[view_name][t]  # ä¸ç¡®å®šæ€§
                C_t = consistencies[t]  # ä¸€è‡´æ€§ï¼ˆè·¨è§†å›¾ï¼Œæ‰€ä»¥æ‰€æœ‰è§†å›¾å…±äº«ï¼‰
                
                # ä¸ç¡®å®šæ€§æƒé‡
                if use_exponential_decay:
                    # æŒ‡æ•°è¡°å‡ï¼šä½ä¸ç¡®å®šæ€§ â†’ é«˜æƒé‡
                    uncertainty_weight = np.exp(-U_r_t)
                else:
                    # å€’æ•°å½¢å¼ï¼šä¹Ÿæ˜¯ä½ä¸ç¡®å®šæ€§ â†’ é«˜æƒé‡
                    uncertainty_weight = 1.0 / (1.0 + U_r_t)
                
                # èšåˆï¼šexp(-U_r(t)) Â· C_r(t) Â· A_r(t)
                # æ³¨æ„ï¼šC_tæ˜¯è·¨è§†å›¾çš„ï¼Œæ‰€ä»¥æ‰€æœ‰è§†å›¾ä½¿ç”¨åŒä¸€ä¸ªC_t
                weighted_sum += uncertainty_weight * C_t * A_r_t
            
            # å¹³å‡
            trust_agg[t] = weighted_sum / R
        
        return trust_agg
    
    @staticmethod
    def compute_trust_aggregated_normalized(
        attributions_by_view: dict,
        uncertainties_by_view: dict,
        consistencies: np.ndarray
    ) -> np.ndarray:
        """
        è®¡ç®—å½’ä¸€åŒ–çš„Trust_aggï¼ˆç»“æœåœ¨[0,1]ä¹‹é—´ï¼‰
        
        Args:
            attributions_by_view: {view_name: attribution[length]}
            uncertainties_by_view: {view_name: uncertainty[length]}
            consistencies: [length]
            
        Returns:
            trust_agg_normalized: [length] å½’ä¸€åŒ–çš„truståˆ†æ•°
        """
        # å…ˆå½’ä¸€åŒ–å„ä¸ªç»„ä»¶
        view_names = list(attributions_by_view.keys())
        
        # å½’ä¸€åŒ–attributions
        normalized_attr = {}
        for view_name in view_names:
            attr = attributions_by_view[view_name]
            attr_abs = np.abs(attr)
            attr_norm = attr_abs / (attr_abs.max() + 1e-8)
            normalized_attr[view_name] = attr_norm
        
        # å½’ä¸€åŒ–uncertainties
        normalized_unc = {}
        for view_name in view_names:
            unc = uncertainties_by_view[view_name]
            unc_norm = unc / (unc.max() + 1e-8)
            normalized_unc[view_name] = unc_norm
        
        # consistencyå·²ç»åœ¨[0,1]èŒƒå›´å†…
        
        # è®¡ç®—trust_agg
        trust_agg = TrustScore.compute_trust_aggregated(
            normalized_attr,
            normalized_unc,
            consistencies,
            use_exponential_decay=True
        )
        
        # å½’ä¸€åŒ–åˆ°[0,1]
        trust_agg_norm = trust_agg / (trust_agg.max() + 1e-8)
        
        return trust_agg_norm


# ==================== æ—¶é—´æ­¥çº§åˆ«ä¸€è‡´æ€§ ====================

class TimestepConsistency:
    """
    Time-step-level Cross-view Consistency
    
    é—®é¢˜ï¼šä¸åŒè§†å›¾åœ¨æ¯ä¸ªæ—¶é—´æ­¥ä¸Šçš„attributionæ˜¯å¦ä¸€è‡´
    æ³¨æ„ï¼šè¿™æ˜¯æ—¶é—´æ­¥çº§åˆ«ï¼Œä¸æ˜¯å…¨å±€ç›¸ä¼¼åº¦
    """
    
    @staticmethod
    def compute_timestep_consistency(
        attributions: Dict[str, np.ndarray],  # {view_name: [length]}
        method: str = 'inverse_std'
    ) -> np.ndarray:
        """
        è®¡ç®—æ¯ä¸ªæ—¶é—´æ­¥çš„è·¨è§†å›¾ä¸€è‡´æ€§
        
        Args:
            attributions: {view_name: attribution[length]}
            method: 'inverse_std', 'inverse_range', 'inverse_cv'
            
        Returns:
            consistency: [length] æ¯ä¸ªæ—¶é—´æ­¥çš„ä¸€è‡´æ€§
        """
        view_names = list(attributions.keys())
        length = attributions[view_names[0]].shape[0]
        
        consistency = np.zeros(length)
        
        for t in range(length):
            # æ”¶é›†è¯¥æ—¶é—´æ­¥åœ¨æ‰€æœ‰viewä¸­çš„å€¼
            values_at_t = np.array([attributions[v][t] for v in view_names])
            
            if method == 'inverse_std':
                # æ ‡å‡†å·®çš„å€’æ•°
                std = np.std(values_at_t)
                consistency[t] = 1.0 / (1.0 + std)
                
            elif method == 'inverse_range':
                # èŒƒå›´çš„å€’æ•°
                value_range = np.ptp(values_at_t)  # peak-to-peak
                consistency[t] = 1.0 / (1.0 + value_range)
                
            elif method == 'inverse_cv':
                # å˜å¼‚ç³»æ•°çš„å€’æ•°
                mean = np.mean(values_at_t)
                std = np.std(values_at_t)
                cv = std / (abs(mean) + 1e-8)
                consistency[t] = 1.0 / (1.0 + cv)
                
            else:
                raise ValueError(f"Unknown method: {method}")
        
        return consistency


# ==================== æ ¸å¿ƒåŒºåˆ†ï¼šä¸‰ä¸ªæ¦‚å¿µ ====================

class ThreeConceptsDistinction:
    """
    æ˜ç¡®åŒºåˆ†ä¸‰ä¸ªæ¦‚å¿µï¼š
    1. Attribution Importanceï¼ˆå½’å› é‡è¦æ€§ï¼‰
    2. Explanation Uncertaintyï¼ˆè§£é‡Šä¸ç¡®å®šæ€§ï¼‰
    3. Trustï¼ˆå¯ä¿¡åº¦ï¼‰
    """
    
    @staticmethod
    def categorize_timesteps(
        attribution: np.ndarray,         # [length] é‡è¦æ€§
        uncertainty: np.ndarray,         # [length] ä¸ç¡®å®šæ€§
        trust: np.ndarray,               # [length] å¯ä¿¡åº¦
        importance_threshold: float = 0.5,
        trust_threshold: float = 0.5
    ) -> Dict[str, np.ndarray]:
        """
        å°†æ—¶é—´æ­¥åˆ†ä¸ºå…«ç±»ï¼ˆ2Ã—2Ã—2ï¼‰
        
        ä½†æœ€å…³é”®çš„å¯¹æ¯”æ˜¯ï¼š
        - High importance + Low uncertainty + Low trust  â†’ ç¨³å®šä½†ä¸å¯ä¿¡
        - High importance + High uncertainty + High trust â†’ ä¸ç¨³å®šä½†å¯ä¿¡
        
        è¿™è¯æ˜äº†ï¼šUncertainty â‰  Trustï¼
        """
        # å½’ä¸€åŒ–
        attr_norm = np.abs(attribution)
        attr_norm = (attr_norm - attr_norm.min()) / (attr_norm.max() - attr_norm.min() + 1e-8)
        
        unc_norm = uncertainty / (uncertainty.max() + 1e-8)
        
        # åˆ†ç±»
        is_important = attr_norm > importance_threshold
        is_uncertain = unc_norm > 0.5  # é«˜ä¸ç¡®å®šæ€§
        is_trusted = trust > trust_threshold
        
        categories = {
            # å…³é”®å¯¹æ¯”1ï¼šç¨³å®šä½†ä¸å¯ä¿¡
            'stable_but_untrusted': np.where(
                is_important & ~is_uncertain & ~is_trusted
            )[0],
            
            # å…³é”®å¯¹æ¯”2ï¼šä¸ç¨³å®šä½†å¯ä¿¡
            'unstable_but_trusted': np.where(
                is_important & is_uncertain & is_trusted
            )[0],
            
            # ç†æƒ³æƒ…å†µï¼šç¨³å®šä¸”å¯ä¿¡
            'stable_and_trusted': np.where(
                is_important & ~is_uncertain & is_trusted
            )[0],
            
            # æœ€å·®æƒ…å†µï¼šä¸ç¨³å®šä¸”ä¸å¯ä¿¡
            'unstable_and_untrusted': np.where(
                is_important & is_uncertain & ~is_trusted
            )[0],
            
            # å…¶ä»–ç±»åˆ«
            'unimportant_stable_trusted': np.where(
                ~is_important & ~is_uncertain & is_trusted
            )[0],
            
            'unimportant_stable_untrusted': np.where(
                ~is_important & ~is_uncertain & ~is_trusted
            )[0],
            
            'unimportant_unstable_trusted': np.where(
                ~is_important & is_uncertain & is_trusted
            )[0],
            
            'unimportant_unstable_untrusted': np.where(
                ~is_important & is_uncertain & ~is_trusted
            )[0],
        }
        
        return categories


# ==================== ä½¿ç”¨ç¤ºä¾‹ ====================

if __name__ == "__main__":
    print("="*70)
    print("æ­£ç¡®çš„Trustå®šä¹‰å’Œå®ç°")
    print("="*70)
    
    print("\næ ¸å¿ƒåŒºåˆ«:")
    print("-"*70)
    print("Explanation Uncertainty:")
    print("  é—®é¢˜: è¿™ä¸ªé‡è¦æ€§åˆ¤æ–­ç¨³ä¸ç¨³ï¼Ÿ")
    print("  æ–¹æ³•: å¤šæ¬¡è®¡ç®—attributionï¼Œçœ‹æ–¹å·®")
    print("  æœ¬è´¨: Attributionæœ¬èº«çš„stability")
    
    print("\nTrust (åŸºç¡€å®šä¹‰):")
    print("  é—®é¢˜: å½“attributionè¯´'é‡è¦'æ—¶ï¼Œè¯¥ä¸è¯¥ä¿¡ï¼Ÿ")
    print("  æ–¹æ³•: æ‰°åŠ¨æ—¶é—´ç‚¹ï¼Œçœ‹æ¨¡å‹è¾“å‡ºæ˜¯å¦çœŸçš„å˜åŒ–")
    print("  æœ¬è´¨: Attributionå£°ç§°çš„å¯éªŒè¯æ€§ï¼ˆclaim verificationï¼‰")
    
    print("\nTrust_agg (èšåˆå®šä¹‰ï¼Œæ¨è):")
    print("  å…¬å¼: Trust_agg(t) = (1/R) Î£_r exp(-U_r(t)) Â· C_r(t) Â· A_r(t)")
    print("  æ•´åˆ: å¤šè§†å›¾ + ä¸ç¡®å®šæ€§ + ä¸€è‡´æ€§ + å½’å› å€¼")
    print("  ä¼˜ç‚¹: è®¡ç®—å¿«é€Ÿï¼Œä¸éœ€è¦é¢å¤–æ‰°åŠ¨")
    
    print("\nå…³é”®æ´å¯Ÿ:")
    print("-"*70)
    print("âŒ Low uncertainty â‰  High trust")
    print("âœ“ Trust_aggè‡ªåŠ¨é™ä½ä¸ç¡®å®šè§†å›¾çš„æƒé‡ï¼ˆexp(-U)ï¼‰")
    print("âœ“ Trust_aggå¼ºè°ƒè·¨è§†å›¾ä¸€è‡´çš„æ—¶é—´æ­¥ï¼ˆCï¼‰")
    print("âœ“ Trust_aggè€ƒè™‘å½’å› å€¼å¤§å°ï¼ˆAï¼‰")
    
    print("\nTrustçš„ä¸¤ç§è®¡ç®—æ–¹å¼:")
    print("-"*70)
    print("1. æ‰°åŠ¨éªŒè¯ï¼ˆç²¾ç¡®ä½†æ…¢ï¼‰:")
    print("   Trust(t|x) = E[ğŸ™(|f(x) - f(x\\Î´_t)| â‰¥ Îµ) | a_t â‰¥ Ï„]")
    
    print("\n2. èšåˆå…¬å¼ï¼ˆå¿«é€Ÿä¸”æœ‰æ•ˆï¼Œæ¨èï¼‰:")
    print("   Trust_agg(t) = (1/R) Î£_r exp(-U_r(t)) Â· C_r(t) Â· A_r(t)")
    print("   - R: è§†å›¾æ•°é‡")
    print("   - U_r(t): è§†å›¾rçš„ä¸ç¡®å®šæ€§")
    print("   - C_r(t): æ—¶é—´æ­¥tçš„è·¨è§†å›¾ä¸€è‡´æ€§")
    print("   - A_r(t): è§†å›¾rçš„å½’å› å€¼")
    
    print("\n" + "="*70)
    print("æ¨¡å—å·²åŠ è½½ï¼Œå¯ä»¥ä½¿ç”¨ï¼š")
    print("  - ExplanationUncertainty: è®¡ç®—è§£é‡Šä¸ç¡®å®šæ€§")
    print("  - TrustScore.compute_trust_all_timesteps: æ‰°åŠ¨éªŒè¯æ–¹æ³•")
    print("  - TrustScore.compute_trust_aggregated: Trust_aggæ–¹æ³•ï¼ˆæ¨èï¼‰")
    print("  - TimestepConsistency: æ—¶é—´æ­¥çº§åˆ«ä¸€è‡´æ€§")
    print("  - ThreeConceptsDistinction: ä¸‰æ¦‚å¿µåŒºåˆ†")
    print("="*70)